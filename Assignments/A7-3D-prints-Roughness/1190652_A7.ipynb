{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Department Of Computer Science\n",
    "    COMP4381, SP.TOP: DATA SCIENCE AND ANALYTICS\n",
    "    Dr. Hussein Soboh\n",
    "    COMP4381 | Section 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=center> Assignment #7 </div>\n",
    "<div align=center><b> 3D prints roughness dataset</b></div>\n",
    "<div align=center>Linear Regression pipeline for the Roughness of the 3D prints</div>\n",
    "\n",
    "    Prepeared by: Sondos Aabed\n",
    "    ID: 1190652"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- Introduction\n",
    "- Tools and Versions\n",
    "- Data Analysis Process\n",
    "    - Data Wrangling\n",
    "    - Data preparation for modeling\n",
    "        - Feature scaling.\n",
    "        - Feature selection.\n",
    "        - Data splitting.\n",
    "- Data Modeling Processing\n",
    "    - Algorithm\n",
    "    - Training \n",
    "    - Testing\n",
    "    - Evaluation\n",
    "        - performance metrics\n",
    "        - bias, variance tradeoff\n",
    "- Insights and Conclusions\n",
    "    \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Working on 3D printed pieces, could face the challenge of having to reinforce them totally or locally in order to improve their strength and durability. It could be a whole part or a specific area subjected to some kind of load, such as compression, tension, shear, torsion, or bending. [1]\n",
    "The aim of the noteboook is to determine how much of the adjustment parameters in 3d printers affect the print quality, accuracy and strenght it's more of a product quality task. Where there are nine setting parameters and three measured output parameters one of which that is the targeted (Roughness)\n",
    "\n",
    "![5l7W9Cj1eGhVgFhuIfNKzirVA2v861pZ4xIW84T4qOw](https://github.com/sondosaabed/SP.TOP-Data-Science-and-Analytics/assets/65151701/cbf8ec7f-7490-4e67-8cfb-b37ac1cf4799)\n",
    "\n",
    "**Figure 1:** Zurikh Artificail parts [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, a dataset of 3D prints roughness and other features is used. The roughness is a measure of how rough the 3D printed part is. It is the target feature for this assignment, where the roughness a numerical value that will be predicted using linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset\n",
    "\n",
    "This dataset comes from research by TR/Selcuk University Mechanical Engineering department.[3]\n",
    "\n",
    "Here is the [Kaggle Link of the Dataset](https://www.kaggle.com/datasets/afumetto/3dprinter/data?select=data.csv)\n",
    "\n",
    "The dataset contains the following features:\n",
    "\n",
    "|Feature|Type|Description|\n",
    "|-----|-----|-----|\n",
    "|Layer Height (mm)| numerical| \n",
    "| Wall Thickness (mm)| numerical|\n",
    "| Infill Density (%)| numerical|Percentage of the object's interior filled with material.|\n",
    "| Infill Pattern ()|ordinal| The geometric pattern used to fill the interior of the object.|\n",
    "| Nozzle Temperature (Cº)|numerical| Temperature of the material exiting the printer nozzle.|\n",
    "| Bed Temperature (Cº)|numerical| Temperature of the printer bed where the object is laid down.|\n",
    "| Print Speed (mm/s)|numerical| Speed at which the printer nozzle travels while printing.|\n",
    "| Material () | nominal | The filament or material used for printing the object.|\n",
    "| Fan Speed (%)|numerical|\n",
    "\n",
    "The target feature is: Roughness (µm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows what is means to have diffrent types of infill patterns and diffrent types of infill densities.\n",
    "![main-qimg-70b737714f100e1b57c6c22d5d60effb](https://github.com/sondosaabed/SP.TOP-Data-Science-and-Analytics/assets/65151701/0c15e3ba-431e-40c0-b0f2-21d0401ad8fe)\n",
    "\n",
    "**Figure 2:** fill patterns in 3D printing [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/sondosaabed/SP.TOP-Data-Science-and-Analytics/assets/65151701/73270f3c-15bd-464e-80f9-37904260d7f3)\n",
    "\n",
    "**Figure 3:** Material PLA vs ABS [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and Versions\n",
    "\n",
    "The following tools and versions are utiliize through this reporting:\n",
    "\n",
    "|Tool | Version |\n",
    "|-----|---------|\n",
    "|Python|3.12.2|\n",
    "|Numpy|1.26.4|\n",
    "|Matplotlib|3.8.2|\n",
    "|Pandas|2.2.1|\n",
    "|Sckitlearn||\n",
    "|Visual Studio Code |Updated|\n",
    "|Git & github|[Repo.](https://github.com/sondosaabed/SP.TOP-Data-Science-and-Analytics/blob/main/Assignments/A7-3D-prints-Roughness/1190652_A7.ipynb)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "\n",
    "In this section, the data wrangling process is followed wehre first the dataset is loaded and it goes through assessment and cleansing. Inluding aspectes of structural probelms and outliers, duplicaes or missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=\"./3d-printing-roughness.csv\"):\n",
    "    \"\"\"\n",
    "    Loads the csv data into the pandas data frame\n",
    "    Args:\n",
    "        path (string): path to the data, deafult value is the file name\n",
    "    Returns:\n",
    "        (pd.DataFrame): data frame contains the file data (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    df = None\n",
    "    if path.endswith(\".csv\"):\n",
    "        df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing and Cleaning the datasets\n",
    "In this section the following steps will be conducted:\n",
    "- Assess and handle Columns and Data types\n",
    "- Assess and handle Duplicates\n",
    "- Assess and handle Missing Values\n",
    "-  Assess and handle Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assessing and handling Columns and Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since one the requiremnts is to have an ordinal feature this feature has the notion of order on it regarding the structure and the infill pattern used where the higher the rank the more complex the pattern used in the design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " for the infill_pattern categorical feature because it have the notion of order the higher means the more complex the structure is we can replace the grid = 0 and honeycomb = 1 instead of one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.infill_pattern = [0 if each == \"grid\" else 1 for each in df.infill_pattern] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the second categorical feature which is the material it doesn't have the notion of order so it had to go through one hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['material'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now all the dataset is numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assess and handle Duplicates\n",
    "Now let's check for duplicates and handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are no duplicates records found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assess and handle Missing Values\n",
    "This is the final section of cleaning the dataset, it is about detecting and handling the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are no missing records found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assess and handle Outliers\n",
    "Now let's check for outliers with visualization using boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='box',figsize=(15, 6));\n",
    "plt.xlabel('Columns')  \n",
    "plt.ylabel('Values') \n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.minorticks_on()\n",
    "plt.suptitle('Figure 4: Boxlotting the 3D prints Roughness Dataset', size=20)\n",
    "plt.tick_params(axis='x', rotation=70) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The print_speed has an upper bound outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['print_speed'].plot(kind='box',figsize=(4, 4));\n",
    "plt.xlabel('Column')  \n",
    "plt.ylabel('Values') \n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.minorticks_on()\n",
    "plt.suptitle('Figure 5: Boxlotting the 3D prints Roughness Dataset', size=20)\n",
    "plt.tick_params(axis='x') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The outlier is the record that has the speed of printing as 120, let's take a further look into the records that has that speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['print_speed']== 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There seem to be many records that have the printing speed of 120, it is decided to keep these records as a reasonable speed of printing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for modeling\n",
    "In this section the following steps will be conducted:\n",
    "- Spliting into testing and training subsets.\n",
    "- Feature scaling.\n",
    "- Feature Selection and correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and correlation\n",
    "Since numerical outliers were detected, the feature scaling will be performed using the standard scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix = pd.plotting.scatter_matrix(df,  figsize=(12, 12), diagonal='kde')\n",
    "plt.suptitle('Figure 6: Scatter Matrix of 3D prints DataFrame', size=20)\n",
    "for ax in scatter_matrix.ravel():\n",
    "    ax.set_xlabel(ax.get_xlabel(), rotation=45, ha='right')\n",
    "    ax.set_ylabel(ax.get_ylabel(), rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It is noticed that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1, cbar=True, linewidths=0.5, square=True)      \n",
    "plt.title('Figure 7: Correlation Matrix of DataFrame', size=20)\n",
    "plt.xticks(rotation=45, ha='right')  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It is noticed that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Splitting\n",
    "The splitting rule used is the 80:20 split train:test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[selected_features]]\n",
    "y = df['roughness']\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1190652)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "Since numerical outliers were detected, the feature scaling will be performed using the standard scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looking at the maximum and minimum values or the range of each of the numerical feature, the data contains diffrent scales of features so the decision is to make the step of feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test))\n",
    "display(X_train_scaled.sample(5))\n",
    "display(X_train_scaled.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now looking at the ranges and the minimum and maximum values they are all in the same scale of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling Process\n",
    "in this section, two linear regression models are trained. Once with all the features and the second one with only the selected features based on the correlation between the features and the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRM1 = LinearRegression() ## All Features\n",
    "LRM2 = LinearRegression() ## Selected Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = LRM1.fit(X_train_scaled,y_train)\n",
    "history2 = LRM2.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1=LRM1.predict(X_test)\n",
    "y_pred_2=LRM2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Vs. Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias, Varianve Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences\n",
    "- [1] https://the3dbros.com/3d-print-infill-patterns-explained/\n",
    "- [2] https://3dsolved.com/how-to-make-stronger-3d-prints-step-by-step-guide/\n",
    "- [3] https://www.kaggle.com/datasets/afumetto/3dprinter/data?select=data.csv\n",
    "- [4] https://www.weforum.org/agenda/2023/11/robotics-3d-printing-smartphones-space-technology-november/\n",
    "- [5] https://3d2go.com.ph/blog/abs-vs-pla-filaments/\n",
    "- [6] https://medium.com/@ahmet17/makina-m%C3%BChendisleri-i%C3%A7in-derin-%C3%B6%C4%9Frenme-3d-printer-veri-setinin-i%CC%87ncelenmesi-6fe1f48e0cdb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
